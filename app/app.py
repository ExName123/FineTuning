# app/app.py
import gradio as gr
import onnxruntime as ort
import numpy as np
from PIL import Image
import torch
from torchvision import transforms
import os
from pathlib import Path
import json

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
def find_best_model():
    """Find the best model based on testing results."""
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    best_model_info_path = Path("../experiments/artifacts/best_model.json")
    
    if best_model_info_path.exists():
        try:
            with open(best_model_info_path, 'r', encoding='utf-8') as f:
                best_model_info = json.load(f)
            best_model_name = best_model_info['name']
            best_accuracy = best_model_info['accuracy']
            
            # –ò—â–µ–º ONNX –≤–µ—Ä—Å–∏—é –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –ø–∞–ø–∫–µ
            onnx_path = Path(f"../experiments/artifacts/plots/best_{best_model_name}.onnx")
            if onnx_path.exists():
                print(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å: {best_model_name} (—Ç–æ—á–Ω–æ—Å—Ç—å: {best_accuracy:.1%})")
                return onnx_path
            else:
                print(f"‚ö†Ô∏è ONNX –≤–µ—Ä—Å–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ –ø—É—Ç–∏: {onnx_path}")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è best_model.json: {e}")
    
    # Fallback: –∏—â–µ–º –ª—é–±—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é ONNX –º–æ–¥–µ–ª—å –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø–∞–ø–∫–∞—Ö
    possible_paths = [
        Path("../experiments/artifacts/plots"),  # –ì–¥–µ —Ä–µ–∞–ª—å–Ω–æ –ª–µ–∂–∞—Ç ONNX —Ñ–∞–π–ª—ã
        Path("../experiments/artifacts"),        # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –ø—Ä–æ–≤–µ—Ä–∏–º –∫–æ—Ä–µ–Ω—å
        Path("../experiments/artifacts/models")  # –ò –ø–∞–ø–∫—É models
    ]
    
    for models_dir in possible_paths:
        if models_dir.exists():
            onnx_files = list(models_dir.glob("best_*.onnx"))
            if onnx_files:
                fallback_model = onnx_files[0]
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –º–æ–¥–µ–ª—å: {fallback_model}")
                return fallback_model
    
    # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏, –∏—â–µ–º —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ –≤–æ –≤—Å–µ—Ö –ø–æ–¥–ø–∞–ø–∫–∞—Ö artifacts
    artifacts_dir = Path("../experiments/artifacts")
    onnx_files = list(artifacts_dir.rglob("best_*.onnx"))
    
    if onnx_files:
        fallback_model = onnx_files[0]
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –º–æ–¥–µ–ª—å (—Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫): {fallback_model}")
        return fallback_model
    
    raise FileNotFoundError(f"No ONNX models found! Searched in: {[str(p) for p in possible_paths]}")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–ª–∞—Å—Å—ã
try:
    with open("../experiments/artifacts/classes.txt", "r", encoding="utf-8") as f:
        CLASSES = [line.strip() for line in f.readlines()]
except Exception as e:
    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–ª–∞—Å—Å–æ–≤: {e}")
    CLASSES = ["minivan", "sedan", "wagon"]

print(f"üéØ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –∫–ª–∞—Å—Å—ã: {CLASSES}")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
try:
    onnx_path = find_best_model()
    session = ort.InferenceSession(str(onnx_path), providers=['CPUExecutionProvider'])
    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {onnx_path.name}")
    print(f"üìÅ –ü–æ–ª–Ω—ã–π –ø—É—Ç—å: {onnx_path.absolute()}")
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
    session = None

# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ (–¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –æ–±—É—á–µ–Ω–∏–µ–º)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225]),
])

def predict(image):
    if session is None:
        return {"Error": "Model not loaded"}
    
    try:
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        image = image.convert('RGB')
        input_tensor = transform(image).unsqueeze(0).numpy()
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        ort_inputs = {session.get_inputs()[0].name: input_tensor}
        ort_outs = session.run(None, ort_inputs)
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        probabilities = torch.softmax(torch.tensor(ort_outs[0]), dim=1)
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results = {CLASSES[i]: float(probabilities[0][i]) for i in range(len(CLASSES))}
        return results
        
    except Exception as e:
        return {"Error": f"Prediction failed: {str(e)}"}

# –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
def create_examples():
    """Create example images list"""
    examples = []
    data_dirs = ["minivan", "sedan", "wagon"]
    
    for class_name in data_dirs:
        class_path = Path(f"../data/raw/{class_name}")
        if class_path.exists():
            images = list(class_path.glob("*.jpg")) + list(class_path.glob("*.png")) + list(class_path.glob("*.jpeg"))
            if images:
                examples.append(str(images[0]))
    
    return examples

app = gr.Interface(
    fn=predict,
    inputs=gr.Image(type="pil", label="–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∞–≤—Ç–æ–º–æ–±–∏–ª—è"),
    outputs=gr.Label(num_top_classes=3, label="–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"),
    title="üöó –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–∏–ø–æ–≤ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π",
    description="–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è, –∏ –º–æ–¥–µ–ª—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç –µ–≥–æ —Ç–∏–ø",
    examples=create_examples() if create_examples() else None
)

if __name__ == "__main__":
    print("üöÄ Starting Gradio app...")
    print("üì± Open http://localhost:7860 in your browser")
    print("üåê Or use: http://127.0.0.1:7860")
    app.launch(server_name="localhost", server_port=7860, share=False)