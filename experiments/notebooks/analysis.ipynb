{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e311b5c0",
   "metadata": {},
   "source": [
    "Compute dataset statistics, mean and std per RGB channel.\n",
    "Save results to artifacts/stats.json for later use in normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cd4614",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def main():\n",
    "    data_dir = Path(\"data/raw\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # размер под модель\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=0)  # <-- важно num_workers=0 на Windows\n",
    "\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    total_images = 0\n",
    "\n",
    "    for images, _ in loader:\n",
    "        batch_samples = images.size(0)  # количество изображений в батче\n",
    "        images = images.view(batch_samples, images.size(1), -1)  # B x C x (H*W)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total_images += batch_samples\n",
    "\n",
    "    mean /= total_images\n",
    "    std /= total_images\n",
    "\n",
    "    mean = mean.tolist()\n",
    "    std = std.tolist()\n",
    "\n",
    "    print(f\"\\nDataset statistics:\")\n",
    "    print(f\"Mean: {mean}\")\n",
    "    print(f\"Std:  {std}\")\n",
    "\n",
    "    Path(\"artifacts\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    stats_path = Path(\"artifacts/stats.json\")\n",
    "    with stats_path.open(\"w\") as f:\n",
    "        json.dump({\"mean\": mean, \"std\": std}, f)\n",
    "\n",
    "    print(f\"\\nStatistics saved to {stats_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce84f55",
   "metadata": {},
   "source": [
    "Config for train.py (hyperparameters, out_dir, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad14149d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataConfig:\n",
    "   \n",
    "    data_root: str = \"data/raw\"\n",
    "    img_size: int = 224\n",
    "    batch_size: int = 16\n",
    "    num_workers: int = 2\n",
    "    train_ratio: float = 0.7\n",
    "    val_ratio: float = 0.15\n",
    "    test_ratio: float = 0.15\n",
    "    \n",
    "    augmentation: bool = True\n",
    "    color_jitter: float = 0.15\n",
    "    random_rotate: int = 10\n",
    "\n",
    "@dataclass  \n",
    "class ModelConfig:\n",
    "   \n",
    "    model_name: str = \"resnet50\"\n",
    "    num_classes: int = 3\n",
    "    pretrained: bool = True\n",
    "    freeze_backbone: bool = True\n",
    "    unfreeze_epoch: int = 5\n",
    "    \n",
    "    # Hyperparameters\n",
    "    learning_rate: float = 0.001\n",
    "    weight_decay: float = 0.01\n",
    "    \n",
    "    @classmethod\n",
    "    def get_learning_rate_space(cls):\n",
    "        return [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "    \n",
    "    @classmethod\n",
    "    def get_weight_decay_space(cls):\n",
    "        return [0.1, 0.01, 0.001, 0.0001, 0.0]\n",
    "    \n",
    "    @classmethod\n",
    "    def get_unfreeze_epoch_space(cls):\n",
    "        return [3, 5, 7, 10]\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    epochs: int = 15\n",
    "    early_stopping_patience: int = 5\n",
    "    \n",
    "    learning_rate: float = 0.001\n",
    "    weight_decay: float = 0.01\n",
    "    momentum: float = 0.9\n",
    "    \n",
    "    seed: int = 42\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    out_dir: str = \"artifacts\"\n",
    "    save_checkpoints: bool = True\n",
    "    log_interval: int = 1\n",
    "    \n",
    "    @classmethod\n",
    "    def get_batch_size_space(cls):\n",
    "        return [8, 16, 32, 64]\n",
    "    \n",
    "    @classmethod  \n",
    "    def get_epochs_space(cls):\n",
    "        return [10, 15, 20, 25]\n",
    "\n",
    "@dataclass\n",
    "class HyperparameterSearchConfig:\n",
    "    search_type: str = \"grid\"\n",
    "    n_trials: int = 8\n",
    "    \n",
    "    learning_rates: List[float] = field(default_factory=lambda: [0.001, 0.0001])\n",
    "    # batch_sizes: List[int] = field(default_factory=lambda: [8, 16, 32])\n",
    "    # weight_decays: List[float] = field(default_factory=lambda: [0.1, 0.01, 0.001, 0.0001])\n",
    "    epochs_list: List[int] = field(default_factory=lambda: [10, 15])\n",
    "    \n",
    "    tuning_epochs: int = 10\n",
    "    patience: int = 3\n",
    "\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    data: DataConfig\n",
    "    model: ModelConfig\n",
    "    train: TrainConfig\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'data': self.data.__dict__,\n",
    "            'model': self.model.__dict__,\n",
    "            'train': self.train.__dict__\n",
    "        }\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dict(cls, config_dict):\n",
    "        return cls(\n",
    "            data=DataConfig(**config_dict['data']),\n",
    "            model=ModelConfig(**config_dict['model']),\n",
    "            train=TrainConfig(**config_dict['train'])\n",
    "        )\n",
    "\n",
    "RESNET50_EXPERIMENT = ExperimentConfig(\n",
    "    data=DataConfig(batch_size=16, img_size=224),\n",
    "    model=ModelConfig(model_name=\"resnet50\", freeze_backbone=True, unfreeze_epoch=5),\n",
    "    train=TrainConfig(epochs=15, learning_rate=0.001, seed=42)\n",
    ")\n",
    "\n",
    "EFFICIENTNET_EXPERIMENT = ExperimentConfig(\n",
    "    data=DataConfig(batch_size=32, img_size=224),\n",
    "    model=ModelConfig(model_name=\"efficientnet_b0\", freeze_backbone=True, unfreeze_epoch=3),\n",
    "    train=TrainConfig(epochs=15, learning_rate=0.001, seed=42)\n",
    ")\n",
    "\n",
    "EXPERIMENT_CONFIGS = {\n",
    "    'resnet50': RESNET50_EXPERIMENT,\n",
    "    'efficientnet_b0': EFFICIENTNET_EXPERIMENT,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d5f01b",
   "metadata": {},
   "source": [
    "analysis.py charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b870a243",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import torch\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def load_model_results():\n",
    "    print(\"UPLOADING MODEL RESULTS\")\n",
    "    \n",
    "    models_info = []\n",
    "    model_names = ['resnet50', 'mobilenetv3_large_100']\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        try:\n",
    "            checkpoint_path = f\"artifacts/models/best_{model_name}.pth\"\n",
    "            \n",
    "            # Исправление для PyTorch 2.6 с weights_only=True\n",
    "            try:\n",
    "                # Сначала пробуем с weights_only=True\n",
    "                checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=True)\n",
    "            except:\n",
    "                # Если не получается, пробуем с weights_only=False (менее безопасно)\n",
    "                print(f\"Warning: Using weights_only=False for {model_name}. Load from trusted source only.\")\n",
    "                checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)\n",
    "            \n",
    "            # Извлекаем метрики из чекпоинта\n",
    "            val_accuracy = checkpoint.get('val_accuracy', 0)\n",
    "            if not val_accuracy:\n",
    "                # Пробуем другие возможные ключи\n",
    "                val_accuracy = checkpoint.get('best_acc', checkpoint.get('accuracy', 0))\n",
    "            \n",
    "            epochs_trained = checkpoint.get('epoch', checkpoint.get('epochs', 0))\n",
    "            \n",
    "            # Подсчет параметров\n",
    "            model_state_dict = checkpoint.get('model_state_dict', checkpoint.get('state_dict', {}))\n",
    "            if model_state_dict:\n",
    "                parameters = sum(p.numel() for p in model_state_dict.values())\n",
    "            else:\n",
    "                parameters = 0\n",
    "            \n",
    "            models_info.append({\n",
    "                'Model': model_name,\n",
    "                'Family': 'ResNet' if 'resnet' in model_name else 'MobileNet',\n",
    "                'Test Accuracy': float(val_accuracy),\n",
    "                'Epochs Trained': int(epochs_trained),\n",
    "                'Parameters': int(parameters)\n",
    "            })\n",
    "            print(f\"{model_name}: Accuracy = {val_accuracy:.4f}, Parameters = {parameters:,}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"{model_name}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(models_info)\n",
    "\n",
    "def load_results_from_csv():\n",
    "    \"\"\"Альтернативный способ загрузки результатов из CSV файлов\"\"\"\n",
    "    print(\"\\nTRYING TO LOAD FROM CSV FILES...\")\n",
    "    \n",
    "    models_info = []\n",
    "    csv_files = {\n",
    "        'resnet50': 'resnet50_tuning_results.csv',\n",
    "        'mobilenetv3_large_100': 'mobilenetv3_large_100_tuning_results.csv'\n",
    "    }\n",
    "    \n",
    "    for model_name, csv_file in csv_files.items():\n",
    "        try:\n",
    "            if os.path.exists(csv_file):\n",
    "                df = pd.read_csv(csv_file)\n",
    "                if not df.empty:\n",
    "                    best_result = df.loc[df['val_acc'].idxmax()]\n",
    "                    \n",
    "                    models_info.append({\n",
    "                        'Model': model_name,\n",
    "                        'Family': 'ResNet' if 'resnet' in model_name else 'MobileNet',\n",
    "                        'Test Accuracy': float(best_result['val_acc']),\n",
    "                        'Epochs Trained': int(best_result.get('epochs', best_result.get('best_epoch', 0))),\n",
    "                        'Parameters': int(estimate_parameters(model_name))\n",
    "                    })\n",
    "                    print(f\"{model_name} from CSV: Accuracy = {best_result['val_acc']:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {csv_file}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(models_info)\n",
    "\n",
    "def estimate_parameters(model_name):\n",
    "    \"\"\"Оценка количества параметров для известных архитектур\"\"\"\n",
    "    param_estimates = {\n",
    "        'resnet50': 25_557_032,\n",
    "        'mobilenetv3_large_100': 5_483_032\n",
    "    }\n",
    "    return param_estimates.get(model_name, 0)\n",
    "\n",
    "def plot_comparison(df):\n",
    "    \"\"\"Create comparison plots.\"\"\"\n",
    "    print(\"\\nCREATING COMPARISON CHARTS\")\n",
    "    \n",
    "    # Создаем директорию для графиков если её нет\n",
    "    os.makedirs('artifacts/plots', exist_ok=True)\n",
    "    \n",
    "    plt.style.use('default')\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # График 1: Сравнение точности\n",
    "    bars = axes[0].bar(df['Model'], df['Test Accuracy'], \n",
    "                      color=['#1f77b4', '#ff7f0e'], alpha=0.7)\n",
    "    axes[0].set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].set_ylim(0, 1)\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        axes[0].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                    f'{height:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # График 2: Количество параметров\n",
    "    if df['Parameters'].sum() > 0:\n",
    "        bars = axes[1].bar(df['Model'], df['Parameters'] / 1e6, \n",
    "                          color=['#2ca02c', '#d62728'], alpha=0.7)\n",
    "        axes[1].set_title('Number of Parameters (Millions)', fontsize=14, fontweight='bold')\n",
    "        axes[1].set_ylabel('Million Parameters')\n",
    "        axes[1].grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            axes[1].text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                        f'{height:.1f}M', ha='center', va='bottom', fontweight='bold')\n",
    "    else:\n",
    "        axes[1].text(0.5, 0.5, 'Parameter data\\nnot available', \n",
    "                    ha='center', va='center', transform=axes[1].transAxes, fontsize=12)\n",
    "        axes[1].set_title('Number of Parameters', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # График 3: Сравнение по семействам\n",
    "    family_acc = df.groupby('Family')['Test Accuracy'].mean()\n",
    "    if len(family_acc) > 1:\n",
    "        bars = axes[2].bar(family_acc.index, family_acc.values,\n",
    "                          color=['#9467bd', '#8c564b'], alpha=0.7)\n",
    "        axes[2].set_title('Accuracy by Model Family', fontsize=14, fontweight='bold')\n",
    "        axes[2].set_ylabel('Average Accuracy')\n",
    "        axes[2].set_ylim(0, 1)\n",
    "        axes[2].grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            axes[2].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                        f'{height:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    else:\n",
    "        axes[2].text(0.5, 0.5, 'Only one model family\\navailable', \n",
    "                    ha='center', va='center', transform=axes[2].transAxes, fontsize=12)\n",
    "        axes[2].set_title('Accuracy by Model Family', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('artifacts/plots/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Graphs saved: artifacts/plots/model_comparison.png\")\n",
    "\n",
    "def generate_report(df):\n",
    "    print(\"\\nANALYTICAL REPORT\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"No data available for analysis\")\n",
    "        return\n",
    "    \n",
    "    best_model = df.loc[df['Test Accuracy'].idxmax()]\n",
    "    \n",
    "    print(\"BASIC METRICS:\")\n",
    "    print(f\"Best Model: {best_model['Model']}\")\n",
    "    print(f\"  - Accuracy: {best_model['Test Accuracy']:.4f} ({best_model['Test Accuracy']*100:.2f}%)\")\n",
    "    print(f\"  - Parameters: {best_model['Parameters']:,}\")\n",
    "    print(f\"  - Family: {best_model['Family']}\")\n",
    "    print(f\"  - Epochs Trained: {best_model['Epochs Trained']}\")\n",
    "    \n",
    "    if len(df) > 1:\n",
    "        fastest_model = df.loc[df['Parameters'].idxmin()]\n",
    "        print(f\"\\nLightest Model: {fastest_model['Model']}\")\n",
    "        print(f\"  - Parameters: {fastest_model['Parameters']:,}\")\n",
    "        print(f\"  - Accuracy: {fastest_model['Test Accuracy']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nFAMILY COMPARISON:\")\n",
    "    family_stats = df.groupby('Family').agg({\n",
    "        'Test Accuracy': ['mean', 'max', 'count'],\n",
    "        'Parameters': 'mean'\n",
    "    }).round(4)\n",
    "    print(family_stats)\n",
    "    \n",
    "    print(f\"\\nKEY INSIGHTS:\")\n",
    "    if len(df) > 1:\n",
    "        accuracy_diff = float(df['Test Accuracy'].max() - df['Test Accuracy'].min())\n",
    "        if df['Parameters'].sum() > 0:\n",
    "            param_ratio = float(df['Parameters'].max() / df['Parameters'].min())\n",
    "            print(f\"Accuracy difference: {accuracy_diff:.4f}\")\n",
    "            print(f\"Parameter ratio: {param_ratio:.1f}x\")\n",
    "            \n",
    "            if accuracy_diff < 0.05:\n",
    "                print(\"RECOMMENDATION: Choose the lighter model (accuracy difference is negligible)\")\n",
    "            else:\n",
    "                print(\"RECOMMENDATION: Choose the more accurate model\")\n",
    "        else:\n",
    "            print(f\"Accuracy difference: {accuracy_diff:.4f}\")\n",
    "            print(\"RECOMMENDATION: Choose model with highest accuracy\")\n",
    "    else:\n",
    "        print(f\"Only one model available: {best_model['Model']}\")\n",
    "        print(f\"Final accuracy: {best_model['Test Accuracy']:.4f}\")\n",
    "\n",
    "def save_results(df):\n",
    "    \"\"\"Save analysis results to JSON\"\"\"\n",
    "    os.makedirs('artifacts', exist_ok=True)\n",
    "    \n",
    "    if df.empty:\n",
    "        results = {'error': 'No data available for analysis'}\n",
    "    else:\n",
    "        best_model = df.loc[df['Test Accuracy'].idxmax()]\n",
    "        \n",
    "        # Конвертируем pandas типы в нативные Python типы\n",
    "        best_model_dict = {}\n",
    "        for key, value in best_model.items():\n",
    "            if pd.isna(value):\n",
    "                best_model_dict[key] = None\n",
    "            elif isinstance(value, (np.integer, pd.Int64Dtype)):\n",
    "                best_model_dict[key] = int(value)\n",
    "            elif isinstance(value, (np.floating, pd.Float64Dtype)):\n",
    "                best_model_dict[key] = float(value)\n",
    "            else:\n",
    "                best_model_dict[key] = value\n",
    "        \n",
    "        # Конвертируем весь DataFrame\n",
    "        comparison_list = []\n",
    "        for _, row in df.iterrows():\n",
    "            row_dict = {}\n",
    "            for key, value in row.items():\n",
    "                if pd.isna(value):\n",
    "                    row_dict[key] = None\n",
    "                elif isinstance(value, (np.integer, pd.Int64Dtype)):\n",
    "                    row_dict[key] = int(value)\n",
    "                elif isinstance(value, (np.floating, pd.Float64Dtype)):\n",
    "                    row_dict[key] = float(value)\n",
    "                else:\n",
    "                    row_dict[key] = value\n",
    "            comparison_list.append(row_dict)\n",
    "        \n",
    "        results = {\n",
    "            'best_model': best_model_dict,\n",
    "            'comparison': comparison_list,\n",
    "            'summary': {\n",
    "                'accuracy_range': [\n",
    "                    float(df['Test Accuracy'].min()), \n",
    "                    float(df['Test Accuracy'].max())\n",
    "                ],\n",
    "                'parameter_range': [\n",
    "                    int(df['Parameters'].min()), \n",
    "                    int(df['Parameters'].max())\n",
    "                ],\n",
    "                'models_tested': int(len(df)),\n",
    "                'best_accuracy': float(best_model['Test Accuracy'])\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    with open('artifacts/analysis_results.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nResults saved: artifacts/analysis_results.json\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main analysis function.\"\"\"\n",
    "    print(\"ANALYSIS OF EXPERIMENTAL RESULTS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Пробуем загрузить из моделей\n",
    "    df = load_model_results()\n",
    "    \n",
    "    # Если не получилось, пробуем из CSV\n",
    "    if df.empty:\n",
    "        print(\"\\nTrying alternative data sources...\")\n",
    "        df = load_results_from_csv()\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"\\nNo data available for analysis\")\n",
    "        print(\"Please check:\")\n",
    "        print(\"1. Model files exist in artifacts/models/\")\n",
    "        print(\"2. CSV files with results exist\")\n",
    "        return\n",
    "    \n",
    "    # Создаем графики\n",
    "    plot_comparison(df)\n",
    "    \n",
    "    # Генерируем отчет\n",
    "    generate_report(df)\n",
    "    \n",
    "    # Сохраняем результаты\n",
    "    save_results(df)\n",
    "    \n",
    "    print(f\"\\nAnalysis completed successfully!\")\n",
    "    print(f\"Check files in artifacts/ directory\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d0db16",
   "metadata": {},
   "source": [
    "test_predictions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e9d5ef",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "def load_model_fixed(model_name, num_classes=3):\n",
    "    \"\"\"Fixed model loading for PyTorch 2.6\"\"\"\n",
    "    try:\n",
    "        if model_name == 'mobilenetv3_large_100':\n",
    "            model = timm.create_model('mobilenetv3_large_100', pretrained=False, num_classes=num_classes)\n",
    "        elif model_name == 'resnet50':\n",
    "            model = timm.create_model('resnet50', pretrained=False, num_classes=num_classes)\n",
    "        else:\n",
    "            print(f\"Unknown model: {model_name}\")\n",
    "            return None\n",
    "            \n",
    "        checkpoint_path = f\"artifacts/models/best_{model_name}.pth\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)\n",
    "        \n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        elif 'state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)\n",
    "        \n",
    "        model.eval()\n",
    "        print(f\"✓ {model_name} loaded successfully\")\n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Model loading error {model_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def predict_image(model, image_path, class_names, transform):\n",
    "    \"\"\"Prediction for single image\"\"\"\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = transform(image).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(image)\n",
    "            probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
    "            predicted_class = torch.argmax(probabilities).item()\n",
    "            confidence = probabilities[predicted_class].item()\n",
    "            \n",
    "        return class_names[predicted_class], confidence\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\", 0.0\n",
    "\n",
    "def main():\n",
    "    print(\"TESTING MODEL PREDICTIONS\")\n",
    "    \n",
    "    class_names = ['minivan', 'sedan', 'wagon']\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    test_images = [\n",
    "        'data/raw/minivan/kisspng-2016-nissan-quest-car-2013-nissan-quest-2011-nissa-5ae78661c06196.926277781525122657788.jpg',\n",
    "        'data/raw/sedan/d2e5f48218cc6572a9388998fa185769.jpg', \n",
    "        'data/raw/wagon/0d1901c8711742e1cb1769c805ad9e8b.jpg'\n",
    "    ]\n",
    "    \n",
    "    print(\"Test Images:\")\n",
    "    for img in test_images:\n",
    "        print(f\"  {os.path.basename(img)}\")\n",
    "    print(f\"Classes: {class_names}\")\n",
    "    \n",
    "    models = {}\n",
    "    for model_name in ['resnet50', 'mobilenetv3_large_100']:\n",
    "        print(f\"\\nLoading: {model_name}\")\n",
    "        model = load_model_fixed(model_name, num_classes=len(class_names))\n",
    "        if model:\n",
    "            models[model_name] = model\n",
    "    \n",
    "    if not models:\n",
    "        print(\"Couldn't load any models\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"PREDICTION RESULTS:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\n{model_name.upper()} PREDICTIONS:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for img_path in test_images:\n",
    "            if os.path.exists(img_path):\n",
    "                predicted_class, confidence = predict_image(model, img_path, class_names, transform)\n",
    "                print(f\"  {os.path.basename(img_path)}:\")\n",
    "                print(f\"    Predicted: {predicted_class}\")\n",
    "                print(f\"    Confidence: {confidence:.2%}\")\n",
    "            else:\n",
    "                print(f\"  {img_path}: File not found\")\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bb3f03",
   "metadata": {},
   "source": [
    "train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a3d869",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Main training script with robust error handling for model downloads.\n",
    "Uses ResNet50 as first model and MobileNetV3 as second model.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Создаем директорию для логов и конфигурируем logger\n",
    "Path(\"artifacts\").mkdir(exist_ok=True)\n",
    "log_file = \"artifacts/training.log\"\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.handlers.clear()  # очищаем обработчики, если что-то было установлено раньше\n",
    "\n",
    "formatter = logging.Formatter(\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "\n",
    "file_handler = logging.FileHandler(log_file, mode=\"w\", encoding=\"utf-8\")\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "stream_handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TIMM_DOWNLOAD_TIMEOUT'] = '30'\n",
    "os.environ['TIMM_DOWNLOAD_RETRY'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision import transforms\n",
    "import argparse       \n",
    "import pandas as pd    \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "from config import DataConfig, HyperparameterSearchConfig, ModelConfig, TrainConfig, ExperimentConfig, EXPERIMENT_CONFIGS\n",
    "\n",
    "\n",
    "class ModelTrainer:\n",
    "    \"\"\"Model trainer with robust error handling.\"\"\"\n",
    "    \n",
    "    def __init__(self, experiment_config: ExperimentConfig):\n",
    "        stats_path = \"artifacts/stats.json\"\n",
    "        if not Path(stats_path).exists():\n",
    "            raise FileNotFoundError(f\"{stats_path} не найден. Сначала запустите compute_stats.py\")\n",
    "    \n",
    "        with open(stats_path, \"r\") as f:\n",
    "            stats = json.load(f)\n",
    "\n",
    "        self.DATA_MEAN = stats[\"mean\"]\n",
    "        self.DATA_STD = stats[\"std\"]\n",
    "\n",
    "        self.config = experiment_config\n",
    "        self.data_cfg = experiment_config.data\n",
    "        self.model_cfg = experiment_config.model\n",
    "        self.train_cfg = experiment_config.train\n",
    "        self.set_seed()\n",
    "        \n",
    "    def set_seed(self):\n",
    "        \"\"\"Fix all random generators for reproducibility.\"\"\"\n",
    "        random.seed(self.train_cfg.seed)\n",
    "        np.random.seed(self.train_cfg.seed)\n",
    "        torch.manual_seed(self.train_cfg.seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(self.train_cfg.seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "    def seed_worker(self, worker_id):\n",
    "        \"\"\"Seed worker for DataLoader reproducibility.\"\"\"\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "        \n",
    "    def setup_data_directories(self):\n",
    "        \"\"\"Create necessary directories.\"\"\"\n",
    "        data_dirs = [\n",
    "            \"data/raw/minivan\",\n",
    "            \"data/raw/sedan\", \n",
    "            \"data/raw/wagon\",\n",
    "            \"artifacts/models\",\n",
    "            \"artifacts/plots\"\n",
    "        ]\n",
    "        \n",
    "        for dir_path in data_dirs:\n",
    "            Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    def check_data_exists(self, data_root):\n",
    "        if not Path(data_root).exists():\n",
    "            print(f\"Directory {data_root} does not exist\")\n",
    "            logger.info(f\"Directory {data_root} does not exist\")\n",
    "            return False\n",
    "            \n",
    "        subdirs = [d for d in Path(data_root).iterdir() if d.is_dir()]\n",
    "        if not subdirs:\n",
    "            print(f\"No class directories in {data_root}!\")\n",
    "            logger.info(f\"No class directories in {data_root}!\")\n",
    "            return False\n",
    "            \n",
    "        print(f\"Data found in: {data_root}\")\n",
    "        logger.info(f\"Data found in: {data_root}\")\n",
    "        total_images = 0\n",
    "        \n",
    "        for subdir in subdirs:\n",
    "            image_extensions = {'.jpg', '.jpeg', '.png', '.webp', '.bmp', '.JPG', '.JPEG', '.PNG', '.WEBP'}\n",
    "            images = [f for f in subdir.iterdir() if f.suffix.lower() in image_extensions and f.is_file()]\n",
    "            \n",
    "            print(f\" {subdir.name}: {len(images)} images\")\n",
    "            logger.info(f\" {subdir.name}: {len(images)} images\")\n",
    "            total_images += len(images)\n",
    "            \n",
    "        print(f\"Total images: {total_images}\")\n",
    "        logger.info(f\"Total images: {total_images}\")\n",
    "        \n",
    "        if total_images < 30:\n",
    "            print(\"Less than 30 images total - may affect model performance\")\n",
    "            logger.info(\"Less than 30 images total - may affect model performance\")\n",
    "            \n",
    "        return total_images > 0\n",
    "        \n",
    "    def get_transforms(self):\n",
    "        if self.data_cfg.augmentation:\n",
    "            train_t = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(self.data_cfg.img_size),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ColorJitter(0.15, 0.15, 0.15, 0.05),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(self.DATA_MEAN, self.DATA_STD)\n",
    "            ])\n",
    "        else:\n",
    "            train_t = transforms.Compose([\n",
    "                transforms.Resize((self.data_cfg.img_size, self.data_cfg.img_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(self.DATA_MEAN, self.DATA_STD)\n",
    "            ])\n",
    "            \n",
    "        val_t = transforms.Compose([\n",
    "            transforms.Resize((self.data_cfg.img_size, self.data_cfg.img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(self.DATA_MEAN, self.DATA_STD)\n",
    "        ])\n",
    "        \n",
    "        return train_t, val_t\n",
    "\n",
    "    def create_data_loaders(self):\n",
    "        \"\"\"Create DataLoaders with full reproducibility.\"\"\"\n",
    "        train_t, val_t = self.get_transforms()\n",
    "        \n",
    "        full_dataset = ImageFolder(self.data_cfg.data_root)\n",
    "        indices = list(range(len(full_dataset)))\n",
    "        labels = [s[1] for s in full_dataset.samples]\n",
    "        \n",
    "        train_idx, test_idx = train_test_split(\n",
    "            indices, \n",
    "            test_size=self.data_cfg.test_ratio, \n",
    "            stratify=labels, \n",
    "            random_state=self.train_cfg.seed\n",
    "        )\n",
    "        train_idx, val_idx = train_test_split(\n",
    "            train_idx, \n",
    "            test_size=self.data_cfg.val_ratio/(1-self.data_cfg.test_ratio),\n",
    "            stratify=[labels[i] for i in train_idx], \n",
    "            random_state=self.train_cfg.seed\n",
    "        )\n",
    "        \n",
    "        train_ds = ImageFolder(self.data_cfg.data_root, transform=train_t)\n",
    "        val_ds = ImageFolder(self.data_cfg.data_root, transform=val_t)\n",
    "        test_ds = ImageFolder(self.data_cfg.data_root, transform=val_t)\n",
    "        \n",
    "        train_subset = Subset(train_ds, train_idx)\n",
    "        val_subset = Subset(val_ds, val_idx)\n",
    "        test_subset = Subset(test_ds, test_idx)\n",
    "        \n",
    "        generator = torch.Generator()\n",
    "        generator.manual_seed(self.train_cfg.seed)\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            train_subset, \n",
    "            batch_size=self.data_cfg.batch_size, \n",
    "            shuffle=True,\n",
    "            num_workers=self.data_cfg.num_workers,\n",
    "            worker_init_fn=self.seed_worker,\n",
    "            generator=generator,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            val_subset, \n",
    "            batch_size=self.data_cfg.batch_size, \n",
    "            shuffle=False,\n",
    "            num_workers=self.data_cfg.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        test_loader = DataLoader(\n",
    "            test_subset, \n",
    "            batch_size=self.data_cfg.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.data_cfg.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        self.classes = full_dataset.classes\n",
    "        print(f\"Classes: {self.classes}\")\n",
    "        logger.info(f\"Classes: {self.classes}\")\n",
    "        print(f\"Dataset split: train={len(train_idx)}, Val={len(val_idx)}, Test={len(test_idx)}\")\n",
    "        logger.info(f\"Dataset split: train={len(train_idx)}, Val={len(val_idx)}, Test={len(test_idx)}\")\n",
    "        \n",
    "        return train_loader, val_loader, test_loader\n",
    "\n",
    "    def create_model(self):\n",
    "        \"\"\"Create model with robust error handling for downloads.\"\"\"\n",
    "        print(f\"Creating model: {self.model_cfg.model_name}\")\n",
    "        logger.info(f\"Creating model: {self.model_cfg.model_name}\")\n",
    "        print(f\"Pretrained: {self.model_cfg.pretrained}\")\n",
    "        logger.info(f\"Pretrained: {self.model_cfg.pretrained}\")\n",
    "        \n",
    "        try:\n",
    "            model = timm.create_model(\n",
    "                self.model_cfg.model_name, \n",
    "                pretrained=self.model_cfg.pretrained, \n",
    "                num_classes=self.model_cfg.num_classes\n",
    "            )\n",
    "            print(f\"Successfully created {self.model_cfg.model_name}\")\n",
    "            logger.info(f\"Successfully created {self.model_cfg.model_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download {self.model_cfg.model_name}: {e}\")\n",
    "            logger.info(f\"Failed to download {self.model_cfg.model_name}: {e}\")\n",
    "            print(\"Falling back to randomly initialized model...\")\n",
    "            logger.info(\"Falling back to randomly initialized model...\")\n",
    "            \n",
    "            model = timm.create_model(\n",
    "                self.model_cfg.model_name, \n",
    "                pretrained=False,  \n",
    "                num_classes=self.model_cfg.num_classes\n",
    "            )\n",
    "            print(f\"Created {self.model_cfg.model_name} with random initialization\")\n",
    "            logger.info(f\"Created {self.model_cfg.model_name} with random initialization\")\n",
    "        \n",
    "        if self.model_cfg.freeze_backbone:\n",
    "            frozen_count = 0\n",
    "            trainable_count = 0\n",
    "            \n",
    "            for name, param in model.named_parameters():\n",
    "                if any(keyword in name for keyword in ['head', 'fc', 'classifier']):\n",
    "                    param.requires_grad = True\n",
    "                    trainable_count += 1\n",
    "                else:\n",
    "                    param.requires_grad = False\n",
    "                    frozen_count += 1\n",
    "                    \n",
    "            print(f\"Freezing: {frozen_count} frozen, {trainable_count} trainable\")\n",
    "            logger.info(f\"Freezing: {frozen_count} frozen, {trainable_count} trainable\")\n",
    "            print(f\"Unfreeze at epoch: {self.model_cfg.unfreeze_epoch}\")\n",
    "            logger.info(f\"Unfreeze at epoch: {self.model_cfg.unfreeze_epoch}\")\n",
    "                    \n",
    "        return model\n",
    "\n",
    "    def unfreeze_model(self, model):\n",
    "        \"\"\"Unfreeze all model parameters.\"\"\"\n",
    "        print(\"Unfreezing all parameters\")\n",
    "        logger.info(\"Unfreezing all parameters\")\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def train_epoch(self, model, loader, criterion, optimizer, device):\n",
    "        \"\"\"Single training epoch.\"\"\"\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        for images, labels in loader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "            \n",
    "        avg_loss = running_loss / len(loader.dataset)\n",
    "        acc = accuracy_score(all_targets, all_preds)\n",
    "        \n",
    "        return avg_loss, acc\n",
    "\n",
    "    def validate(self, model, loader, criterion, device):\n",
    "        \"\"\"Validate model.\"\"\"\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in loader:\n",
    "                images = images.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "                all_preds.extend(preds)\n",
    "                all_targets.extend(labels.cpu().numpy())\n",
    "                \n",
    "        avg_loss = running_loss / len(loader.dataset)\n",
    "        acc = accuracy_score(all_targets, all_preds)\n",
    "        cm = confusion_matrix(all_targets, all_preds)\n",
    "        report = classification_report(all_targets, all_preds, \n",
    "                                     target_names=self.classes, \n",
    "                                     zero_division=0)\n",
    "        \n",
    "        return avg_loss, acc, cm, report\n",
    "\n",
    "    def train(self):\n",
    "        print(f\"\\nTraining {self.model_cfg.model_name}\")\n",
    "        logger.info(f\"\\nTraining {self.model_cfg.model_name}\")\n",
    "        \n",
    "        train_loader, val_loader, test_loader = self.create_data_loaders()\n",
    "        \n",
    "        model = self.create_model()\n",
    "        model = model.to(self.train_cfg.device)\n",
    "        \n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        print(f\"Parameters: {trainable_params:,} trainable / {total_params:,} total\")\n",
    "        logger.info(f\"Parameters: {trainable_params:,} trainable / {total_params:,} total\")\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = AdamW(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            lr=self.model_cfg.learning_rate,\n",
    "            weight_decay=self.model_cfg.weight_decay\n",
    "        )\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=self.train_cfg.epochs)\n",
    "        \n",
    "        history = {\n",
    "            'train_loss': [], 'val_loss': [],\n",
    "            'train_acc': [], 'val_acc': [],\n",
    "            'learning_rates': []\n",
    "        }\n",
    "        best_val_acc = 0.0\n",
    "        \n",
    "        print(f\"\\nTraining for {self.train_cfg.epochs} epochs on {self.train_cfg.device}\")\n",
    "        logger.info(f\"\\nTraining for {self.train_cfg.epochs} epochs on {self.train_cfg.device}\")\n",
    "        \n",
    "        for epoch in range(self.train_cfg.epochs):\n",
    "            if epoch == self.model_cfg.unfreeze_epoch and self.model_cfg.freeze_backbone:\n",
    "                print(f\"\\nEpoch {epoch}: unfreezing backbone\")\n",
    "                logger.info(f\"\\nEpoch {epoch}: unfreezing backbone\")\n",
    "                self.unfreeze_model(model)\n",
    "                optimizer = AdamW(\n",
    "                    model.parameters(),\n",
    "                    lr=self.model_cfg.learning_rate/10,\n",
    "                    weight_decay=self.model_cfg.weight_decay\n",
    "                )\n",
    "                scheduler = CosineAnnealingLR(optimizer, T_max=self.train_cfg.epochs - epoch)\n",
    "            \n",
    "            train_loss, train_acc = self.train_epoch(\n",
    "                model, train_loader, criterion, optimizer, self.train_cfg.device\n",
    "            )\n",
    "            \n",
    "            val_loss, val_acc, cm, report = self.validate(\n",
    "                model, val_loader, criterion, self.train_cfg.device\n",
    "            )\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['train_acc'].append(train_acc)\n",
    "            history['val_acc'].append(val_acc)\n",
    "            history['learning_rates'].append(optimizer.param_groups[0]['lr'])\n",
    "            \n",
    "            if (epoch + 1) % self.train_cfg.log_interval == 0:\n",
    "                print(f\"Epoch {epoch+1}/{self.train_cfg.epochs}: \"\n",
    "                      f\"Train Loss: {train_loss:.4f}, accuracy: {train_acc:.4f} | \"\n",
    "                      f\"Val Loss: {val_loss:.4f}, accuracy: {val_acc:.4f}\")\n",
    "                logger.info(f\"Epoch {epoch+1}/{self.train_cfg.epochs}: \"\n",
    "                            f\"Train Loss: {train_loss:.4f}, accuracy: {train_acc:.4f} | \"\n",
    "                            f\"Val Loss: {val_loss:.4f}, accuracy: {val_acc:.4f}\")\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                self.save_model(model, epoch, val_acc)\n",
    "                if (epoch + 1) % self.train_cfg.log_interval == 0:\n",
    "                    print(f\"New best model Val accuracy: {val_acc:.4f}\")\n",
    "                    logger.info(f\"New best model Val accuracy: {val_acc:.4f}\")\n",
    "        \n",
    "        final_metrics = self.final_evaluation(model, test_loader, criterion)\n",
    "        self.plot_results(history, cm)\n",
    "        \n",
    "        return history, final_metrics\n",
    "\n",
    "    def save_model(self, model, epoch, accuracy):\n",
    "        \"\"\"Save model with experiment info.\"\"\"\n",
    "        Path(self.train_cfg.out_dir).mkdir(parents=True, exist_ok=True)\n",
    "        Path(f\"{self.train_cfg.out_dir}/models\").mkdir(exist_ok=True)\n",
    "        Path(f\"{self.train_cfg.out_dir}/plots\").mkdir(exist_ok=True)\n",
    "        \n",
    "        model_path = f\"{self.train_cfg.out_dir}/models/best_{self.model_cfg.model_name}.pth\"\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'classes': self.classes,\n",
    "            'config': self.config.to_dict(),\n",
    "            'seed': self.train_cfg.seed,\n",
    "            'val_accuracy': accuracy,\n",
    "            'epoch': epoch\n",
    "        }, model_path)\n",
    "        \n",
    "        with open(f\"{self.train_cfg.out_dir}/classes.txt\", 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(self.classes))\n",
    "        \n",
    "        print(f\"Model saved: {model_path}\")\n",
    "        logger.info(f\"Model saved: {model_path}\")\n",
    "\n",
    "    def final_evaluation(self, model, test_loader, criterion):\n",
    "        \"\"\"Final evaluation on test set.\"\"\"\n",
    "        test_loss, test_acc, test_cm, test_report = self.validate(\n",
    "            model, test_loader, criterion, self.train_cfg.device\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nFinal test result:\")\n",
    "        logger.info(f\"\\nFinal test result:\")\n",
    "        print(f\"   Test loss: {test_loss:.4f}\")\n",
    "        logger.info(f\"   Test loss: {test_loss:.4f}\")\n",
    "        print(f\"   Test accuracy: {test_acc:.4f}\")\n",
    "        logger.info(f\"   Test accuracy: {test_acc:.4f}\")\n",
    "        print(\"\\nClassification report:\")\n",
    "        logger.info(\"\\nClassification report:\")\n",
    "        print(test_report)\n",
    "        logger.info(test_report)\n",
    "        \n",
    "        return {\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc,\n",
    "            'confusion_matrix': test_cm,\n",
    "            'report': test_report\n",
    "        }\n",
    "\n",
    "    def plot_results(self, history, cm):\n",
    "        \"\"\"Plot training results and confusion matrix with best epoch annotation.\"\"\"\n",
    "        Path(f\"{self.train_cfg.out_dir}/plots\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        best_epoch = int(np.argmax(history['val_acc']))\n",
    "        best_val_acc = history['val_acc'][best_epoch]\n",
    "        best_lr = history['learning_rates'][best_epoch] if 'learning_rates' in history else None\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "        axes[0].plot(history['train_loss'], label='Train loss', linewidth=2, color='tab:blue')\n",
    "        axes[0].plot(history['val_loss'], label='Validation loss', linewidth=2, color='tab:orange')\n",
    "        axes[0].axvline(best_epoch, color='gray', linestyle='--', alpha=0.7)\n",
    "        axes[0].set_title('Graph of the loss function (loss)', fontsize=12)\n",
    "        axes[0].set_xlabel('Epoch', fontsize=10)\n",
    "        axes[0].set_ylabel('Value Loss', fontsize=10)\n",
    "        axes[0].legend(loc='best')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "        axes[1].plot(history['train_acc'], label='Train accuracy', linewidth=2, color='tab:green')\n",
    "        axes[1].plot(history['val_acc'], label='Validation accuracy', linewidth=2, color='tab:red')\n",
    "        axes[1].axvline(best_epoch, color='gray', linestyle='--', alpha=0.7)\n",
    "        axes[1].annotate(\n",
    "            f\"Best epoch: {best_epoch + 1}\\nVal acc = {best_val_acc:.4f}\\nLR = {best_lr:.6f}\",\n",
    "            xy=(best_epoch, best_val_acc),\n",
    "            xytext=(best_epoch + 0.5, best_val_acc - 0.05),\n",
    "            arrowprops=dict(arrowstyle='->', color='gray'),\n",
    "            fontsize=9,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8)\n",
    "        )\n",
    "        axes[1].set_title('Graph accuracy', fontsize=12)\n",
    "        axes[1].set_xlabel('Epoch', fontsize=10)\n",
    "        axes[1].set_ylabel('The proportion of correct answers', fontsize=10)\n",
    "        axes[1].legend(loc='best')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[2],\n",
    "                    xticklabels=self.classes, yticklabels=self.classes)\n",
    "        axes[2].set_xlabel('Predicted class', fontsize=10)\n",
    "        axes[2].set_ylabel('The true class', fontsize=10)\n",
    "        axes[2].set_title('Confusion Matrix', fontsize=12)\n",
    "\n",
    "        summary_text = (\n",
    "            f\"Best epoch: {best_epoch + 1} | \"\n",
    "            f\"Val acc = {best_val_acc:.4f}\"\n",
    "            + (f\" | Learning rate = {best_lr:.6f}\" if best_lr is not None else \"\")\n",
    "        )\n",
    "        fig.suptitle(summary_text, fontsize=13, fontweight='bold', y=1.02)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plot_path = f\"{self.train_cfg.out_dir}/plots/{self.model_cfg.model_name}_training.png\"\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Plots (loss/acc/confusion) saved: {plot_path}\")\n",
    "        logger.info(f\"Plots (loss/acc/confusion) saved: {plot_path}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def export_onnx(model_name, num_classes, img_size=224):\n",
    "        \"\"\"Export model to ONNX format.\"\"\"\n",
    "        device = torch.device(\"cpu\")\n",
    "        model_path = f\"artifacts/models/best_{model_name}.pth\"\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"Model {model_path} not found for ONNX export\")\n",
    "            logger.info(f\"Model {model_path} not found for ONNX export\")\n",
    "            return False\n",
    "            \n",
    "        try:\n",
    "            checkpoint = torch.load(model_path, map_location=device)\n",
    "            model = timm.create_model(model_name, pretrained=False, num_classes=num_classes)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            model.eval().to(device)\n",
    "            \n",
    "            dummy_input = torch.randn(1, 3, img_size, img_size, device=device)\n",
    "            onnx_path = f\"artifacts/best_{model_name}.onnx\"\n",
    "            \n",
    "            torch.onnx.export(\n",
    "                model, dummy_input, onnx_path,\n",
    "                input_names=['input'],\n",
    "                output_names=['output'],\n",
    "                dynamic_axes={\n",
    "                    'input': {0: 'batch_size'},\n",
    "                    'output': {0: 'batch_size'}\n",
    "                },\n",
    "                opset_version=12\n",
    "            )\n",
    "            print(f\"ONNX model exported: {onnx_path}\")\n",
    "            logger.info(f\"ONNX model exported: {onnx_path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"ONNX export failed for {model_name}: {e}\")\n",
    "            logger.info(f\"ONNX export failed for {model_name}: {e}\")\n",
    "            return False\n",
    "\n",
    "\n",
    "def get_alternative_model_config():\n",
    "    \"\"\"Get configuration for alternative model (MobileNetV3).\"\"\"\n",
    "    return ExperimentConfig(\n",
    "        data=DataConfig(batch_size=32, img_size=224),\n",
    "        model=ModelConfig(\n",
    "            model_name=\"mobilenetv3_large_100\",  \n",
    "            num_classes=3,\n",
    "            pretrained=True,\n",
    "            freeze_backbone=True,\n",
    "            unfreeze_epoch=3,\n",
    "            learning_rate=0.001,\n",
    "            weight_decay=0.01\n",
    "        ),\n",
    "        train=TrainConfig(epochs=15, seed=42)\n",
    "    )\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--tune\", action=\"store_true\", help=\"Run hyperparameter tuning\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    seed = 42\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    print(\"\\nCar classification training\")\n",
    "    logger.info(\"\\nCar classification training\")\n",
    "    print(\"Using ResNet50 + MobileNetV3 as models\")\n",
    "    logger.info(\"Using ResNet50 + MobileNetV3 as models\")\n",
    "\n",
    "    trainer = ModelTrainer(EXPERIMENT_CONFIGS['resnet50'])\n",
    "    trainer.setup_data_directories()\n",
    "\n",
    "    if not trainer.check_data_exists(\"data/raw\"):\n",
    "        print(\"\\nPlease add your images to:\")\n",
    "        logger.info(\"\\nPlease add your images to:\")\n",
    "        print(\"   data/raw/minivan/  (30+ images)\")\n",
    "        logger.info(\"   data/raw/minivan/  (30+ images)\")\n",
    "        print(\"   data/raw/sedan/    (30+ images)\")\n",
    "        logger.info(\"   data/raw/sedan/    (30+ images)\")\n",
    "        print(\"   data/raw/wagon/    (30+ images)\")\n",
    "        logger.info(\"   data/raw/wagon/    (30+ images)\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    models_to_try = [\n",
    "        ('resnet50', EXPERIMENT_CONFIGS['resnet50']),\n",
    "        ('mobilenetv3_large_100', get_alternative_model_config()),\n",
    "    ]\n",
    "\n",
    "    if args.tune:\n",
    "        hpcfg = HyperparameterSearchConfig()\n",
    "        for model_name, exp_cfg in models_to_try:\n",
    "            print(f\"\\nHyperparameter tunning for {model_name.upper()}\")\n",
    "            logger.info(f\"\\nHyperparameter tunning for {model_name.upper()}\")\n",
    "            results = []\n",
    "\n",
    "            for lr in hpcfg.learning_rates:\n",
    "                for ep in hpcfg.epochs_list:\n",
    "                    print(f\"\\nTraining {model_name} with lr={lr}, epochs={ep}\")\n",
    "                    logger.info(f\"\\nTraining {model_name} with lr={lr}, epochs={ep}\")\n",
    "\n",
    "                    exp_cfg.model.learning_rate = lr\n",
    "                    exp_cfg.train.epochs = ep\n",
    "\n",
    "                    trainer = ModelTrainer(exp_cfg)\n",
    "                    try:\n",
    "                        history, metrics = trainer.train()\n",
    "                        val_acc = metrics['test_acc']\n",
    "                        val_cm = metrics['confusion_matrix']\n",
    "\n",
    "                        cm_path = f\"artifacts/plots/{model_name}_lr{lr}_ep{ep}_cm.png\"\n",
    "                        plt.figure(figsize=(5, 5))\n",
    "                        sns.heatmap(\n",
    "                            val_cm,\n",
    "                            annot=True,\n",
    "                            fmt='d',\n",
    "                            cmap='Blues',\n",
    "                            xticklabels=trainer.classes,\n",
    "                            yticklabels=trainer.classes\n",
    "                        )\n",
    "                        plt.title(f\"{model_name} | lr={lr}, epochs={ep}\")\n",
    "                        plt.xlabel(\"Predicted\")\n",
    "                        plt.ylabel(\"True\")\n",
    "                        plt.tight_layout()\n",
    "                        plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
    "                        plt.close()\n",
    "                        print(f\"Confusion matrix saved: {cm_path}\")\n",
    "                        logger.info(f\"Confusion matrix saved: {cm_path}\")\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Training failed for {model_name} (lr={lr}, ep={ep}): {e}\")\n",
    "                        logger.info(f\"Training failed for {model_name} (lr={lr}, ep={ep}): {e}\")\n",
    "                        val_acc = 0.0\n",
    "\n",
    "                    results.append({\n",
    "                        'model': model_name,\n",
    "                        'lr': lr,\n",
    "                        'epochs': ep,\n",
    "                        'val_acc': val_acc\n",
    "                    })\n",
    "\n",
    "            df = pd.DataFrame(results)\n",
    "            csv_path = f\"artifacts/{model_name}_tuning_results.csv\"\n",
    "            df.to_csv(csv_path, index=False)\n",
    "            print(f\"Saved results: {csv_path}\")\n",
    "            logger.info(f\"Saved results: {csv_path}\")\n",
    "\n",
    "            best_row = df.loc[df['val_acc'].idxmax()]\n",
    "            best_lr = best_row['lr']\n",
    "            best_ep = int(best_row['epochs'])\n",
    "            print(f\"\\nBest for {model_name}: lr={best_lr}, epochs={best_ep}, acc={best_row['val_acc']:.4f}\")\n",
    "            logger.info(f\"\\nBest for {model_name}: lr={best_lr}, epochs={best_ep}, acc={best_row['val_acc']:.4f}\")\n",
    "\n",
    "            exp_cfg.model.learning_rate = best_lr\n",
    "            exp_cfg.train.epochs = best_ep\n",
    "            print(f\"Retraining {model_name} with best params...\")\n",
    "            logger.info(f\"Retraining {model_name} with best params...\")\n",
    "            trainer = ModelTrainer(exp_cfg)\n",
    "            trainer.train()\n",
    "\n",
    "    else:\n",
    "        results = {}\n",
    "        successful_models = []\n",
    "\n",
    "        for model_name, exp_config in models_to_try:\n",
    "            print(f\"Processing model: {model_name.upper()}\")\n",
    "            logger.info(f\"Processing model: {model_name.upper()}\")\n",
    "\n",
    "            try:\n",
    "                trainer = ModelTrainer(exp_config)\n",
    "                history, metrics = trainer.train()\n",
    "\n",
    "                results[model_name] = {\n",
    "                    'history': history,\n",
    "                    'metrics': metrics\n",
    "                }\n",
    "                successful_models.append(model_name)\n",
    "\n",
    "                export_success = ModelTrainer.export_onnx(model_name, exp_config.model.num_classes)\n",
    "                if export_success:\n",
    "                    print(f\"{model_name} - Training and export completed\")\n",
    "                    logger.info(f\"{model_name} - Training and export completed\")\n",
    "                else:\n",
    "                    print(f\"{model_name} - Training completed but ONNX export failed\")\n",
    "                    logger.info(f\"{model_name} - Training completed but ONNX export failed\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"{model_name} training failed: {e}\")\n",
    "                logger.info(f\"{model_name} training failed: {e}\")\n",
    "                if model_name == 'resnet50':\n",
    "                    print(\"First model failed. Stopping execution.\")\n",
    "                    logger.info(\"First model failed. Stopping execution.\")\n",
    "                    sys.exit(1)\n",
    "                else:\n",
    "                    print(\"continuing...\")\n",
    "                    logger.info(\"continuing...\")\n",
    "                    continue\n",
    "\n",
    "        print(\"Summary\")\n",
    "        logger.info(\"Summary\")\n",
    "\n",
    "        if successful_models:\n",
    "            print(\"Successfully trained models:\")\n",
    "            logger.info(\"Successfully trained models:\")\n",
    "            for model_name in successful_models:\n",
    "                test_acc = results[model_name]['metrics']['test_acc']\n",
    "                print(f\"{model_name}: Test accuracy = {test_acc:.4f}\")\n",
    "                logger.info(f\"{model_name}: Test accuracy = {test_acc:.4f}\")\n",
    "\n",
    "            if len(successful_models) > 1:\n",
    "                best_model = max(successful_models, key=lambda x: results[x]['metrics']['test_acc'])\n",
    "                best_acc = results[best_model]['metrics']['test_acc']\n",
    "                print(f\"\\nBest model: {best_model} with accuracy {best_acc:.4f}\")\n",
    "                logger.info(f\"\\nBest model: {best_model} with accuracy {best_acc:.4f}\")\n",
    "        else:\n",
    "            print(\"No models were successfully trained\")\n",
    "            logger.info(\"No models were successfully trained\")\n",
    "\n",
    "        print(f\"\\nResults saved in: artifacts/\")\n",
    "        logger.info(f\"\\nResults saved in: artifacts/\")\n",
    "        print(\"Training completed successfully!\")\n",
    "        logger.info(\"Training completed successfully!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
